{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Ensuring that PyTorch is using GPU:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GeForce GTX 1080 Ti'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Unline tensorflow, pytorch doesn't utilize the ENTIRE gpu memory, allocation is based on the need__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.0219e+38,  4.5558e-41, -2.0219e+38],\n",
      "        [ 4.5558e-41,  1.4602e-19,  1.8617e+25],\n",
      "        [ 1.1835e+22,  4.3066e+21,  6.3828e+28],\n",
      "        [ 1.4603e-19,  1.1578e+27,  1.1362e+30],\n",
      "        [ 7.1547e+22,  4.5828e+30,  1.2121e+04]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(5, 3)\n",
    "print(x) # near-zero values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1767, 0.3975, 0.7138, 0.4463],\n",
      "        [0.5489, 0.7115, 0.3990, 0.6018],\n",
      "        [0.8468, 0.3822, 0.1215, 0.3374]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(3, 4) # random unif~[0,1]\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(5, 3, dtype=torch.long) # specify datatype , i.e., long\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__List or array to torch tensor__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 4.1000,  2.3000],\n",
      "        [-1.8000,  0.0000]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[4.1, 2.3], [-1.8, 0.]], dtype=torch.float32)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "x = x.new_ones(3, 4) # a new tensor of ones with the same datatype as x\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6., 6., 6., 6.],\n",
      "        [6., 6., 6., 6.],\n",
      "        [6., 6., 6., 6.]])\n"
     ]
    }
   ],
   "source": [
    "x = x.new_full([3, 4], fill_value = 6.0)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2289, 0.9430, 0.8979, 0.2686],\n",
      "        [0.1695, 0.7795, 0.0257, 0.4358],\n",
      "        [0.6815, 0.5553, 0.3924, 0.0191]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand_like(x) # random-unif, same dims and same datatype as x\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0524, 0.8893, 0.8063, 0.0722],\n",
       "        [0.0287, 0.6076, 0.0007, 0.1899],\n",
       "        [0.4644, 0.3084, 0.1540, 0.0004]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4579, 1.8861, 1.7959, 0.5373],\n",
       "        [0.3390, 1.5589, 0.0514, 0.8716],\n",
       "        [1.3629, 1.1107, 0.7849, 0.0383]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1310, -1.2842,  1.1554, -1.3247],\n",
      "        [ 0.3521,  0.4458, -0.5820,  0.4713],\n",
      "        [-0.7978, -0.9127, -0.4194, -0.6050]])\n"
     ]
    }
   ],
   "source": [
    "y = torch.randn_like(x) # random normal\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.add(x, y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = x.add(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3599, -0.3411,  2.0534, -1.0560],\n",
      "        [ 0.5216,  1.2253, -0.5563,  0.9072],\n",
      "        [-0.1163, -0.3573, -0.0269, -0.5859]])\n"
     ]
    }
   ],
   "source": [
    "torch.add(x, y, out=z) # store output in tensor z\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3599, -0.3411,  2.0534, -1.0560],\n",
       "        [ 0.5216,  1.2253, -0.5563,  0.9072],\n",
       "        [-0.1163, -0.3573, -0.0269, -0.5859]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in place addition - use understore '_'\n",
    "y.add_(x) # y = y + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3599, -0.3411,  2.0534, -1.0560],\n",
       "        [ 0.5216,  1.2253, -0.5563,  0.9072],\n",
       "        [-0.1163, -0.3573, -0.0269, -0.5859]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "__Resize/reshape tensor, using view__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(4, 4)\n",
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 8])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x.view([2, 8])\n",
    "y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = x.view(-1, 16)  # the size -1 implies infer from other dimensions\n",
    "z.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Torch Tensor and NumPy array __will share their underlying memory locations, and changing one will change the other.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "b = a.numpy() # convert to numpy array\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 3., 3., 3., 3.])\n",
      "[3. 3. 3. 3. 3.]\n"
     ]
    }
   ],
   "source": [
    "a.mul_(3.) # modify torch tensor 'a', both variables are modified\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.ones(7)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1., 1., 1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "b = torch.from_numpy(a) # from numpy to torch tensor\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = torch.tensor(a) # this way of conversion doesnt correspond to shared memory locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.5000, 4.5000, 4.5000, 4.5000, 4.5000, 4.5000, 4.5000], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "c.add_(3.5)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1.] tensor([1., 1., 1., 1., 1., 1., 1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All the Tensors on the CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CUDA Tensors: Tensors can be moved onto any device using the `.to` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.1355,  0.8372, -0.3998, -0.2384],\n",
      "        [ 1.7906,  0.5579,  2.0107,  0.9068],\n",
      "        [ 0.7952,  1.4420,  1.3234, -0.7406],\n",
      "        [-0.9798, -0.0655, -0.1357,  0.1003]], device='cuda:0')\n",
      "tensor([[ 2.1355,  0.8372, -0.3998, -0.2384],\n",
      "        [ 1.7906,  0.5579,  2.0107,  0.9068],\n",
      "        [ 0.7952,  1.4420,  1.3234, -0.7406],\n",
      "        [-0.9798, -0.0655, -0.1357,  0.1003]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# let us run this cell only if CUDA is available\n",
    "# We will use ``torch.device`` objects to move tensors in and out of GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # a CUDA device object\n",
    "    \n",
    "    # create a tensor DIRECTLY on GPU\n",
    "    y = torch.ones_like(x, device=device)  \n",
    "    \n",
    "    # OR just use strings ``.to(\"cuda\")`` if you want to port to another device after creation \n",
    "    x = x.to(device)               \n",
    "    \n",
    "    z = x + y # z is by default on GPU\n",
    "    \n",
    "    print(z)\n",
    "    \n",
    "    # Transfer it to CPU \n",
    "    print(z.to(\"cpu\", torch.double))       # ``.to`` can also change dtype together!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.1355,  0.8372, -0.3998, -0.2384],\n",
       "        [ 1.7906,  0.5579,  2.0107,  0.9068],\n",
       "        [ 0.7952,  1.4420,  1.3234, -0.7406],\n",
       "        [-0.9798, -0.0655, -0.1357,  0.1003]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.cpu() # on cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.1355,  0.8372, -0.3998, -0.2384],\n",
       "        [ 1.7906,  0.5579,  2.0107,  0.9068],\n",
       "        [ 0.7952,  1.4420,  1.3234, -0.7406],\n",
       "        [-0.9798, -0.0655, -0.1357,  0.1003]], device='cuda:0')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.cuda() # on gpu, 0 implies 1st GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The __rank of a tensor__ refers to the number of dimensions present within the tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(z.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
