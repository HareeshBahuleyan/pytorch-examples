{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7faf52d70950>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "torch.manual_seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_ix = {'hello': 0, 'world': 1}\n",
    "embeds = nn.Embedding(2, 5) # 2 embedding vectors of 5d\n",
    "lookup_tensor = torch.tensor([word_to_ix['hello']], dtype=torch.long)\n",
    "hello_embed = embeds(lookup_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.0260, -2.0655, -1.2054, -0.9122, -1.2502]], grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hello_embed # This was a randomly initialized value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-Gram Language Model\n",
    "$p(w_i | w _{i-1}, w _{i-2})$ --`bigram language model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTEXT_SIZE = 2\n",
    "EMBEDDING_DIM = 10\n",
    "\n",
    "# We will use Shakespeare Sonnet 2\n",
    "test_sentence = \"\"\"When forty winters shall besiege thy brow,\n",
    "And dig deep trenches in thy beauty's field,\n",
    "Thy youth's proud livery so gazed on now,\n",
    "Will be a totter'd weed of small worth held:\n",
    "Then being asked, where all thy beauty lies,\n",
    "Where all the treasure of thy lusty days;\n",
    "To say, within thine own deep sunken eyes,\n",
    "Were an all-eating shame, and thriftless praise.\n",
    "How much more praise deserv'd thy beauty's use,\n",
    "If thou couldst answer 'This fair child of mine\n",
    "Shall sum my count, and make my old excuse,'\n",
    "Proving his beauty by succession thine!\n",
    "This were to be new made when thou art old,\n",
    "And see thy blood warm when thou feel'st it cold.\"\"\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we should tokenize the input, but we will ignore that for now\n",
    "# build a list of tuples.  Each tuple is ([ word_i-2, word_i-1 ], target word)\n",
    "\n",
    "trigrams = [([test_sentence[i-2], test_sentence[i-1]], \n",
    "             test_sentence[i]) for i in range(2, len(test_sentence))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['When', 'forty'], 'winters')]\n"
     ]
    }
   ],
   "source": [
    "print(trigrams[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set(test_sentence)\n",
    "word_to_ix = {word: i for i, word in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NGramLanguageModeler(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, embedding_dim, context_size):\n",
    "        super(NGramLanguageModeler, self).__init__()\n",
    "        \n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        # concatenate the embeddings of w_2 and w_1\n",
    "        self.linear1 = nn.Linear(context_size * embedding_dim, 128) \n",
    "        self.linear2 = nn.Linear(128, vocab_size) # final softmax layer\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        embeds = self.embeddings(inputs).view((1, -1)) # reshape it from [2, emb-dim] to [1, 2*emb-dim]\n",
    "        out = F.relu(self.linear1(embeds))\n",
    "        out = self.linear2(out)\n",
    "        log_probs = F.log_softmax(out, dim = 1) # 0th dim is batch-size\n",
    "        return log_probs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "loss_function = nn.NLLLoss()\n",
    "\n",
    "model = NGramLanguageModeler(vocab_size = len(vocab), \n",
    "                             embedding_dim = EMBEDDING_DIM,\n",
    "                             context_size = CONTEXT_SIZE\n",
    "                            )\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[522.3382515907288, 519.8384222984314, 517.3549876213074, 514.887852191925, 512.4363434314728, 509.9990186691284, 507.5758202075958, 505.16576862335205, 502.7680060863495, 500.381174325943]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    total_loss = 0\n",
    "    \n",
    "    for context, target in trigrams:\n",
    "        \n",
    "        # convert words to idx which are torch tensors\n",
    "        context_ids = torch.tensor([word_to_ix[w] for w in context], \n",
    "                                   dtype=torch.long)\n",
    "        \n",
    "        # reset gradients to zero\n",
    "        model.zero_grad()\n",
    "        \n",
    "        log_probs = model.forward(inputs=context_ids)\n",
    "        \n",
    "        # loss function \n",
    "        loss = loss_function(log_probs, torch.tensor([word_to_ix[target]], dtype=torch.long))\n",
    "        \n",
    "        # backprop and weight update\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item() # sum the loss from individual samples to get epoch level loss\n",
    "        \n",
    "    losses.append(total_loss)\n",
    "    \n",
    "print(losses)\n",
    "                                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Loss')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CBOW\n",
    "Given the previous and next word (surrounding words), predict the current word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['We', 'are', 'to', 'study'], 'about'), (['are', 'about', 'study', 'the'], 'to'), (['about', 'to', 'the', 'idea'], 'study'), (['to', 'study', 'idea', 'of'], 'the'), (['study', 'the', 'of', 'a'], 'idea')]\n"
     ]
    }
   ],
   "source": [
    "CONTEXT_SIZE = 2  # 2 words to the left, 2 to the right\n",
    "raw_text = \"\"\"We are about to study the idea of a computational process.\n",
    "Computational processes are abstract beings that inhabit computers.\n",
    "As they evolve, processes manipulate other abstract things called data.\n",
    "The evolution of a process is directed by a pattern of rules\n",
    "called a program. People create programs to direct processes. In effect,\n",
    "we conjure the spirits of the computer with our spells.\"\"\".split()\n",
    "\n",
    "# By deriving a set from `raw_text`, we deduplicate the array\n",
    "vocab = set(raw_text)\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
    "data = []\n",
    "for i in range(2, len(raw_text) - 2):\n",
    "    context = [raw_text[i - 2], raw_text[i - 1],\n",
    "               raw_text[i + 1], raw_text[i + 2]]\n",
    "    target = raw_text[i]\n",
    "    data.append((context, target))\n",
    "print(data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBOW(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, context_size):\n",
    "        super(CBOW, self).__init__()\n",
    "        \n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        # concatenate the embeddings of w_2 and w_1\n",
    "        self.linear1 = nn.Linear(2 * context_size * embedding_dim, 128) \n",
    "        self.linear2 = nn.Linear(128, vocab_size) # final softmax layer\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embeds = self.embeddings(inputs).view((1, -1)) \n",
    "        out = F.relu(self.linear1(embeds))\n",
    "        out = self.linear2(out)\n",
    "        log_probs = F.log_softmax(out, dim = 1) # 0th dim is batch-size\n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "loss_function = nn.NLLLoss()\n",
    "\n",
    "model = CBOW(vocab_size = vocab_size, \n",
    "             embedding_dim = EMBEDDING_DIM,\n",
    "             context_size = CONTEXT_SIZE\n",
    "            )\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[228.44770002365112, 226.82502269744873, 225.2153458595276, 223.61829257011414, 222.03282570838928, 220.45676517486572, 218.88988304138184, 217.33286833763123, 215.78503894805908, 214.24438190460205]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    total_loss = 0\n",
    "    \n",
    "    for context, target in data:\n",
    "        \n",
    "        # convert words to idx which are torch tensors\n",
    "        context_ids = torch.tensor([word_to_ix[w] for w in context], \n",
    "                                   dtype=torch.long)\n",
    "        \n",
    "        # reset gradients to zero\n",
    "        model.zero_grad()\n",
    "        \n",
    "        log_probs = model.forward(inputs=context_ids)\n",
    "        \n",
    "        # loss function \n",
    "        loss = loss_function(log_probs, torch.tensor([word_to_ix[target]], dtype=torch.long))\n",
    "        \n",
    "        # backprop and weight update\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item() # sum the loss from individual samples to get epoch level loss\n",
    "        \n",
    "    losses.append(total_loss)\n",
    "    \n",
    "print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
